[Overview](./00_overview.md) | [ML Workflow](./01_mlworkflow.md) | [Supervised techniques](./02_supervisedtechniques.md) | [Model Evaluation I](./03_modelevaluationA.md)  | [Model Evaluation II](./04_modelevaluationB.md) | [Closeout](./05_closeout.md)

# Evaluating the models (Cont.)

| *20 min*  |
| --------- |

|Question: What can we do to overcome underfitting and overfitting?  |
| ------------------------------------------------------------------- |

We will briefly discuss **regularisation** as a method to penalise the parameters of the model (degrees of freedom) in order to produce a simpler model. It brings a tradeoff between increasing the bias (avoiding underfitting) and decreasing the variance (avoiding overfitting).

## Some ML packages and open libraries

- Scikit-learn: machine learning in python.
- StatsModels: Python for statistical models.
- Imbalanced-learn: ML for imbalanced datasets in python.
- Shogun: machine learning library that supports many languages.
- Spark MLlib: for scalable machine learning applications.
- H2O: For fraud and tend predictions.
- GoLearn: To build machine learning in Go language.
- DeepLearn.js: Hardware accelerate machine intelligence for javaScript.

