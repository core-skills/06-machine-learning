[Overview](./00_overview.md) | [ML Workflow](./01_mlworkflow.md) | [Supervised techniques](./02_supervisedtechniques.md) | [Model Evaluation I](./03_modelevaluationA.md)  | [Model Evaluation II](./04_modelevaluationB.md) | [Closeout](./05_closeout.md)

# Takeaways & Reflection

Today we've:
- Reviewed the data science basic overflow and discussed the machine learning steps.
- Learned the domain of three supervised ML techniques: SVMs, KNN, and Random Forest.
- Learned how we can evaluate the models and what we can do to improve the performance.
- Discussed the importance of checking if our model is underfitting or overfitting.
- Applied hands-on using Python notebooks which provided implementation of all models and steps discussed in class.

In Data science, it is usually necessary to spend considerable time in cleaning/tidying the data, checking the assumptions, checking whether the questions fit the data, and understanding the problem. Once these steps are performed accordingly, there is a high chance we will be able to choose the appropriate ML model and achieve good performance. In summary, we should remember that:

- Understanding the problem is the most crucial step. 
- Training set should be representative of the problem and should contain relevant features.
- Devote a time to explore the structure of the data.
- Data matters more than algorithms for complex problems.
- Noise in your data can affect learning process, enhancing the probability of overfitting.
- Simple models can give plausible results and should be tested first. 
- If the "test set" contributed to any aspect during the learning process, it is not a "test set", and assessment of future outcomes might be compromised.
- If you data set is biased, your learning algorithm will produce a biased outcome as well (sampling bias problem). 
