{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iron Ore Dataset\n",
    "\n",
    "In this notebook we are going to use the dataset **Iron Ore** explored in week **05-simple-predictions** to illustrate the machine learning techniques:\n",
    " - K-nearest neighbors (K-NN)\n",
    " - Random Forest\n",
    " - Support Vector Machines:\n",
    "     - Linear Kernel\n",
    "     - Radial Basis Function (RBF) Kernel\n",
    "     - Polynomial Kernel\n",
    "     \n",
    "As this dataset is not for classification, we borrow from week **05-simple-predictions** the code below to transform the problem into a classification problem:\n",
    "\n",
    "```python\n",
    "# Splits from oscar Fe>60%, SiO2<9, Al2O3<2, P<0.08\n",
    "split_points = [\n",
    "    ('FE', 60, [False, True]),\n",
    "    ('SIO2', 9, [True, False]),\n",
    "    ('AL2O3', 2, [True, False]),\n",
    "    ('P', 0.08, [True, False]),  \n",
    "]\n",
    "\n",
    "# It's ore if everything is True\n",
    "df['is_ore'] = np.vstack([\n",
    "    pandas.cut(df[elem], bins=[0, split, 100], labels=is_ore)\n",
    "    for elem, split, \n",
    "```\n",
    "\n",
    "In order to have a clean notebook, some functions are implemented in the file *utils.py* (e.g., plot_decision_boundary). We are not going to discuss the implementation aspects of these functions as it is not the scope, but you can to explore and read the content of the functions later on.\n",
    "\n",
    "Summary:\n",
    " - [Data Processing](#data_processing)\n",
    " - [Splitting the Data into Train and Test Sets](#split)\n",
    " - [Data Normalisation](#normalisation)\n",
    " - [Building the Classifiers](#models)\n",
    "     - [K-nearest neighbors (K-NN)](#knn)\n",
    "     - [Random Forest](#rdf)\n",
    "     - [Support Vector Machines](#svm)\n",
    "  \n",
    "  \n",
    "__All the libraries used in this notebook are <font color='red'>Open Source</font>__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "<a id=data_processing></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION** - if running this notebook using JupyterHub, maybe we might need first to install some modules. If so, uncomment the code below and run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas numpy matplotlib seaborn sklearn imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np  # written in C, is faster and robust library for numerical and matrix operations\n",
    "import pandas as pd # data manipulation library, it is widely used for data analysis and relies on numpy library.\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import seaborn as sns # plot nicely =)\n",
    "\n",
    "# Auxiliar functions\n",
    "from utils import *\n",
    "\n",
    "# the following to lines will tell to the python kernel to always update the kernel for every utils.py\n",
    "# modification, without the need of restarting the kernel.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# using the 'inline' backend, your matplotlib graphs will be included in your notebook, next to the code\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use [Pandas](https://pandas.pydata.org/) for the data processing. The function  [read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) is going to be used to read the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataset\n",
    "df = pd.read_csv('../data/iron_ore_study.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we transform this dataset into a **classification task** using the strategy adopted in week **05-simple-predictions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits from oscar Fe>60%, SiO2<9, Al2O3<2, P<0.08\n",
    "split_points = [\n",
    "    ('FE', 60, [False, True]),\n",
    "    ('SIO2', 9, [True, False]),\n",
    "    ('AL2O3', 2, [True, False]),\n",
    "    ('P', 0.08, [True, False]),  \n",
    "]\n",
    "\n",
    "# It's ore if everything is True\n",
    "df['is_ore'] = np.vstack([\n",
    "    pd.cut(df[elem], bins=[0, split, 100], labels=is_ore)\n",
    "    for elem, split, is_ore in split_points\n",
    "]).sum(axis=0) == 4\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column **is_ore** was created to label each sample (row). Next, let's analyse the distribution of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='is_ore', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will:\n",
    "1. store the labels in the variable *y* (ie, the column 'is_ore' of *df*).\n",
    "2. remove the labels from the original dataframe *df*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"is_ore\"].copy(deep=True) # set the variable 'y' to store the labels\n",
    "\n",
    "# removing is_ore from the dataframe \n",
    "list_lbl = ['is_ore'] # list with columns to drop. In that case, it is only one. \n",
    "df = df.drop(list_lbl,axis = 1 )\n",
    "df.head()\n",
    "\n",
    "# we are going to use the function unique, from numpy, to count the number of \n",
    "# unique labels in the dataset. This returns the sorted unique elements of an array and \n",
    "# by setting the parameter 'return_count' will return the number of occurencies\n",
    "# of each unique label\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "print('is ore == {}:'.format(unique[0]), counts[0])\n",
    "print('is ore == {}:'.format(unique[1]), counts[1])\n",
    "print('Proportion:', round(counts[0] / counts[1], 2), ': 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the distribution of labels in *y* is the same as in *df* (as plotted above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data into Train and Test Sets\n",
    "<a id=split></a>\n",
    "\n",
    "First, we need to split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #split arrays or matrices into random train and test subsets\n",
    "\n",
    "# split data train 70% and test 30%. You can try other splits here.\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, y, test_size=0.3, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# The function 'describe' in pandas summarizes the central tendency, dispersion and \n",
    "# shape of a dataset’s distribution, excluding NaN values.\n",
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Your turn!**\n",
    "\n",
    "1. Plot the distribution of the *y* variables, for both the train and test sets.\n",
    "2. Compare them. Can you see the expected result given the choice *test_size=0.3*? \n",
    "3. Can you plot the distribution (of True and False) for the *x* variables by simply using sns.countplot() command? \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalisation\n",
    "<a id=normalisation></a>\n",
    "\n",
    "As we can see in the table above (describe()), the *mean*, the *min* and *max* values are different between all the features. In order to remove this amplitude variation we are going to **standardize** all the features (ie, zero mean and unity variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "#Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train) # not considering the label is_ore; using the training data set!\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**For you!** \n",
    "\n",
    "1. Note that we trained the *scaler* using the **train** dataset not the **test** dataset in the line *scaler.fit(x_train)*. Why?\n",
    "2. Are the new variables Pandas DataFrames? If not, what are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing the central tendency, dispersion and \n",
    "# shape of a dataset’s distribution.\n",
    "\n",
    "aux = pd.DataFrame(x_train_scaled) # building a dataframe (just for convenience)\n",
    "aux.columns = df.columns.tolist()  # including names for the columns\n",
    "aux.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**For you!**\n",
    "1. Compare, with a visualisation, the original data with their scaled versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Classifiers\n",
    "<a id=models></a>\n",
    "\n",
    "So far, we just preprocessed the dataset. Now, we are going to build the following classifiers:\n",
    " - [K-Nearest Neighbors (K-NN)](#knn)\n",
    " - [Random Forest](#rdf)\n",
    " - [Support Vector Machines](#svm)\n",
    "     - [Linear Kernel](#linear)\n",
    "     - [Radial Basis Function Kernel](#rbf)\n",
    "     - [Polynomial Kernel](#poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (K-NN)\n",
    "<a id=knn></a>\n",
    "\n",
    "In short, a new instance is classified in this algorithm by a majority vote according its neighbors. The instance is assigned to the most common class among its *K* nearest neighbors.\n",
    "\n",
    "<img src=\"imgs/knn.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.neighbors.classification import KNeighborsClassifier #Classifier implementing the k-nearest neighbors vote.\n",
    "from sklearn.neighbors import KNeighborsClassifier # as for version 0.22\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=3) # considering k=3    \n",
    "\n",
    "clf_knn.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **decision boundary** illustrates how the model classifies the *samples*. To plot it, we are going to use the function *plot_decision_boundary* implemented in our auxiliar library *utils.py* (feel free to review the code for clarifications). The colormap indicates the probability that a sample belongs to class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_decision_boundary receives the training set (x_train_scaled), the labels (y_train) and\n",
    "# the classifier (clf_knn) and plots the decision bounbary by projecting the data into 2 dimensions using \n",
    "# PCA (Principal Component Analysis)\n",
    "plot_decision_boundary(x_train=x_train_scaled, \n",
    "                       y_train=y_train, \n",
    "                       estimator=clf_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the model, we are going to visualise the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) and compute its **accuracy**. \n",
    "\n",
    "Accuracy is just a ratio of correctly predicted observations w.r.t the total number of observations\n",
    "\n",
    "$AC = \\frac{TP + TN}{P + N}$\n",
    "\n",
    "where:\n",
    "* *TP* and *TN* are the number of correct identifyed samples (true positive plus true negative, equivalent to true \"label 1 cases\" plus true \"label 2 cases\").\n",
    "* *P* and *N* are the total of positive (label 1) cases and negative (label 2) cases, respectively. \n",
    "\n",
    "It is considered the most intuitive performance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries:\n",
    "#  accuracy_score: computes the accuracy classification score.\n",
    "#  confusion_matrix: computes confusion matrix to evaluate the accuracy of a classification\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "ac = accuracy_score(y_test, clf_knn.predict(x_test_scaled))\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, clf_knn.predict(x_test_scaled))\n",
    "\n",
    "# plotting\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "plt.xlabel(\"Actual class\")\n",
    "plt.ylabel(\"predicted class\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Your Turn:\n",
    "\n",
    "1) Try to plot the decision boundaries for different values of *k* and see if you can find any difference with respect to the previoua plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Now check the accuracies. Can you find a value of k that results in a higher accuracy (previous one was 97%)?\n",
    "\n",
    "Plot the confusion matrix if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) The parameter *weights* in K-NN defines the type of method we are going to use. By default, scikit-learn defines the weights as ‘uniform’. However, we can change this parameter to 'distance' to use the algorithm weighted K-NN discussed in our class. Change this parameter to 'distance' and see what happens (plot the decision boundary and print the accuracy). \n",
    "\n",
    "\n",
    "For more information, K-NN documentation can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "<a id=rdf></a>\n",
    "\n",
    "The Decition Trees are examples of information-based learning. It seeks for the most informative feature to split the dataset. The Random Forest classifier builds multiple decision trees and merges them together to get a more accurate and stable prediction (less proned to overfit).\n",
    "\n",
    "<img src=\"imgs/randomForest.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # implements random forest.\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=2)  # 2 trees in the forest.    \n",
    "clf_rf.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's have a look at the **decision boundary**. It helps us to get insights about how the classifier is partioning the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(x_train_scaled, y_train, clf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check the **confusion matrix** and compute the **accuracy** of Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries:\n",
    "#  accuracy_score: computes the accuracy classification score.\n",
    "#  confusion_matrix: computes confusion matrix to evaluate the accuracy of a classification\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix # calling the libraries again, just in case \n",
    "                                                             # you decided to not run kNN cell\n",
    "\n",
    "ac = accuracy_score(y_test, clf_rf.predict(x_test_scaled))\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test,clf_rf.predict(x_test_scaled))\n",
    "\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "plt.xlabel(\"Actual class\")\n",
    "plt.ylabel(\"predicted class\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Your Turn: \n",
    "\n",
    "1) Try to plot the decision boundary for different *n_estimators* and see what you find out. There are other hyperparameters of Random Forest and Decision Trees that you can also try, for instance the *max_depth*. Have a look at the Random Forest [documentation](http://scikit-learn.org/stable/modules/ensemble.html) to check how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) How do you compare the performance with the K-NN? Did you find a better combination of hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "<a id=svm></a>\n",
    "\n",
    "SVM are powerful discriminative classifiers formally defined by the concept of maximing a separating hyperplane. Given labeled training data, the algorithm outputs an optimal hyperplane which categorizes new examples.\n",
    "\n",
    "<img src=\"imgs/svm.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "SVM use the kernel trick to project the data to another space by using the **kernel** in order to perform the (linear) classification. Indeed, kernels are the secret source that makes SVMs interesting ML techniques. In this notebook, we are going to explore three different types of kernels:\n",
    " - [Linear Kernel](#linear)\n",
    " - [Radial Basis Function Kernel](#rbf)\n",
    " - [Polynomial Kernel](#poly)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Kernel\n",
    "<a id=linear></a>\n",
    "\n",
    "The Linear kernel is the simplest kernel function. It is given by the inner product:\n",
    "\n",
    "$$\\mathcal{K}(x,y) = x^Ty$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # implements the Support Vector Machine\n",
    "\n",
    "# Important note: \n",
    "#   SVC implementation is based on libsvm. The fit time complexity is more than quadratic \n",
    "#   with the number of samples which makes it hard to scale to dataset with more than a couple of \n",
    "#   10000 samples.\n",
    "# source: http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#\n",
    "#LinearSVC is based on liblinear, offering an optimized implementation for linear SVMs. It does not support the kernel trick,\n",
    "#but its time complexity scales almost linear w.r.t. the number of instances and features.\n",
    "\n",
    "# linear svm\n",
    "# in order to plot the decision boundaries, we MUST set probability = True.\n",
    "clf_linear = SVC(kernel = 'linear', C=0.01, probability = True)\n",
    "\n",
    "clf_linear.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM **decision boundary**. \n",
    "\n",
    "__PS: make sure that <font color='blue'>probability</font> was defined as <font color='green'>True</font>. Otherwise, *plot_decision_boundary* will raise an error as we are using *predict_proba*__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_decision_boundary receives the training set (x_train_scaled), the labels (y_train) and\n",
    "# the classifier (clf_knn) and plots the decision bounbary by projecting the data to 2 dimension by using \n",
    "# PCA (Principal Components Analysis)\n",
    "plot_decision_boundary(x_train_scaled, y_train, clf_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix** and **accuracy** for SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries:\n",
    "#  accuracy_score: computes the accuracy classification score.\n",
    "#  confusion_matrix: computes confusion matrix to evaluate the accuracy of a classification\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix # calling the libraries again, just in case \n",
    "                                                             # you decided to not run kNN and RDF cells\n",
    "    \n",
    "ac = accuracy_score(y_test, clf_linear.predict(x_test_scaled))\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, clf_linear.predict(x_test_scaled))\n",
    "\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "plt.xlabel(\"Actual class\")\n",
    "plt.ylabel(\"predicted class\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Your Turn:\n",
    "\n",
    "1) Try to plot the decision boundary for different values of *C*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compute the accuracy and show if the SVM could outperform Random Forest or K-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Kernel\n",
    "<a id=poly></a>\n",
    "\n",
    "The Polynomial kernel are well suited for problems where all the training data is normalized.\n",
    "\n",
    "$$\\mathcal{K}(x,y) = (\\gamma x^Ty+r)^d$$\n",
    "\n",
    "in which $\\gamma$ is the slope, $r$ a constant term and the $d$ a polynomial degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # implements the Support Vector Machine\n",
    "\n",
    "# Important note: \n",
    "#   SVC implementation is based on libsvm. The fit time complexity is more than quadratic \n",
    "#   with the number of samples which makes it hard to scale to dataset with more than a couple of \n",
    "#   10000 samples.\n",
    "# source: http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#LinearSVC is based on liblinear, offering an optimized implementation for linear SVMs. It does not support the kernel trick,\n",
    "#but its time complexity scales almost linear w.r.t. the number of instances and features.\n",
    "\n",
    "# in order to plot the decision boundaries, we MUST set probability = True.\n",
    "# coef0 is the constant term r\n",
    "clf_poly = SVC(kernel = 'poly', C=1.4, gamma=0.005, coef0=1.2, degree=5, probability = True)\n",
    "\n",
    "clf_poly.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision boundary** for the poly kernel. \n",
    "\n",
    "__PS: make sure that <font color='blue'>probability</font> was defined as <font color='green'>True</font>. Otherwise, *plot_decision_boundary* will raise an error as we are using *predict_proba*__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(x_train_scaled, y_train, clf_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix** and **accuracy** of the poly kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries:\n",
    "#  accuracy_score: computes the accuracy classification score.\n",
    "#  confusion_matrix: computes confusion matrix to evaluate the accuracy of a classification\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix # calling the libraries again, just in case \n",
    "                                                             # you decided to not run kNN and RF cells\n",
    "    \n",
    "ac = accuracy_score(y_test, clf_poly.predict(x_test_scaled))\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, clf_poly.predict(x_test_scaled))\n",
    "\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "plt.xlabel(\"Actual class\")\n",
    "plt.ylabel(\"predicted class\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Your Turn:\n",
    "\n",
    "1) Try to plot the decision boundary or check the accuracy for different _C_, *degree*, *coef0* and *gamma* values. What was the best classifier so far?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radial Basis Function Kernel\n",
    "<a id=rbf></a>\n",
    "\n",
    "The Radial Basis Function (RBF)  popular kernel function used in SVM and it is given by the following equation:\n",
    "\n",
    "$$\\mathcal{K}(x,y) = \\exp(-\\gamma\\|x-y\\|^2)$$\n",
    "in which $\\gamma=\\frac{1}{2\\sigma^2}$. Note that $sigma$ plays an important role here and should be carefully tuned to the problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # implements the Support Vector Machine\n",
    "\n",
    "# Important note: \n",
    "#   SVC implementation is based on libsvm. The fit time complexity is more than quadratic \n",
    "#   with the number of samples which makes it hard to scale to dataset with more than a couple of \n",
    "#   10000 samples.\n",
    "# source: http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#LinearSVC is based on liblinear, offering an optimized implementation for linear SVMs. It does not support the kernel trick,\n",
    "#but its time complexity scales almost linear w.r.t. the number of instances and features.\n",
    "\n",
    "# in order to plot the decision boundaries, we MUST set probability = True.\n",
    "clf_rbf = SVC(kernel = 'rbf', C=0.01, gamma=0.1, probability = True)\n",
    "\n",
    "clf_rbf.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting takes time!\n",
    "plot_decision_boundary(x_train_scaled, y_train, clf_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries:\n",
    "#  accuracy_score: computes the accuracy classification score.\n",
    "#  confusion_matrix: computes confusion matrix to evaluate the accuracy of a classification\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix # calling the libraries again, just in case \n",
    "                                                             # you decided to not run kNN and RF cells\n",
    "    \n",
    "ac = accuracy_score(y_test, clf_rbf.predict(x_test_scaled))\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, clf_rbf.predict(x_test_scaled))\n",
    "\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "plt.xlabel(\"Actual class\")\n",
    "plt.ylabel(\"predicted class\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Your Turn:\n",
    "\n",
    "1) Try to plot the decision boundary for different *C* and *gamma* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Check the accuracies.\n",
    "\n",
    "Plot the confusion matrix if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "268.15px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
